{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importation des bibliothéques nécessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import pyodbc \n",
    "import os\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "from sqlalchemy import (\n",
    "    create_engine, Column, Integer, String, Float, ForeignKey, Table, MetaData\n",
    ")\n",
    "from sqlalchemy.orm import declarative_base\n",
    "import requests\n",
    "from geopy.geocoders import Nominatim\n",
    "import aiohttp\n",
    "import asyncio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract():\n",
    "    try:\n",
    "        #Fetching sales_2022 data from the database\n",
    "        cnx = pyodbc.connect(\n",
    "            'DRIVER={SQL Server};SERVER=server_name;DATABASE=database_name;Trusted_Connection=yes;'\n",
    "        )\n",
    "        sales_2022_data = pd.read_sql(\n",
    "            'SELECT sale_id, product_id, customer_id, quantity, sale_date, price FROM sales2022', \n",
    "            cnx\n",
    "        )\n",
    "        print(\"Successfully fetched sales_2022 data.\")\n",
    "    except pyodbc.Error as e:\n",
    "        print(f\"Database error: {e}\")\n",
    "        sales_2022_data = None\n",
    "    except Exception as ex:\n",
    "        print(f\"General error: {ex}\")\n",
    "        sales_2022_data = None\n",
    "    finally:\n",
    "        if 'cnx' in locals() and cnx is not None:\n",
    "            cnx.close()\n",
    "\n",
    "    try:\n",
    "        #Fetching sales_2023 data from the csv file\n",
    "        sales_2023_data = pd.read_csv('./data/raw/sales_2023.csv')\n",
    "        print(\"Successfully loaded sales_2023 data.\")\n",
    "    except Exception as ex:\n",
    "        print(f\"Error loading sales_2023 data: {ex}\")\n",
    "        sales_2023_data = None\n",
    "\n",
    "    try:\n",
    "        #Fetching customer data from the csv file\n",
    "        customer_data = pd.read_csv('./data/raw/customer_data.csv')\n",
    "        print(\"Successfully loaded customer data.\")\n",
    "    except Exception as ex:\n",
    "        print(f\"Error loading customer data: {ex}\")\n",
    "        customer_data = None\n",
    "\n",
    "    try:\n",
    "        #Fetching product data from the json file\n",
    "        product_data = pd.read_json('./data/raw/products_data.json')\n",
    "        print(\"Successfully loaded product data.\")\n",
    "    except Exception as ex:\n",
    "        print(f\"Error loading product data: {ex}\")\n",
    "        product_data = None\n",
    "\n",
    "    return sales_2022_data, sales_2023_data, customer_data, product_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "async def get_country_from_city_async(city):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        async with session.get(f'https://api.opencagedata.com/geocode/v1/json?q={city}&key=9f69324b1cdb4efebd80d2b31d24920b') as response:\n",
    "            data = await response.json()\n",
    "            if data['status']['code'] == 200:\n",
    "                country = data['results'][0]['components'].get('country')\n",
    "                return city, country\n",
    "            return city, None\n",
    "\n",
    "async def get_all_countries(cities):\n",
    "    tasks = [get_country_from_city_async(city) for city in cities]\n",
    "    return await asyncio.gather(*tasks)\n",
    "\n",
    "\n",
    "async def transform(sales_2022, sales_2023, product_data, customer_data):\n",
    "    \n",
    "    #Convert sale_date to consistent format in sales_2022\n",
    "    sales_2022['sale_date'] = pd.to_datetime(\n",
    "        sales_2022['sale_date'], \n",
    "        errors='coerce').dt.date\n",
    "\n",
    "    #Merge sales_2022 and sales_2023\n",
    "    sales_data = pd.concat([sales_2022, sales_2023], axis=0)\n",
    "    sales_data.drop(columns=['sale_id'], inplace=True)\n",
    "\n",
    "    #Merge with product_data\n",
    "    sales_data = sales_data.merge(\n",
    "        product_data[['product_id', 'price', 'cost']],\n",
    "        on='product_id',\n",
    "        suffixes=('_sale', '_product')\n",
    "    )\n",
    "\n",
    "    #Calculate revenue and profit\n",
    "    sales_data['revenue'] = sales_data['price_sale'] * sales_data['quantity']\n",
    "    sales_data['profit'] = sales_data['revenue'] - (sales_data['cost'] * sales_data['quantity'])\n",
    "\n",
    "    #Create time dimension from sales_data\n",
    "    unique_dates = sales_data['sale_date'].dropna().unique()\n",
    "    date_range = pd.to_datetime(unique_dates)\n",
    "    time_dim = pd.DataFrame({'date': date_range})\n",
    "    time_dim['date_id'] = range(1, len(time_dim) + 1)\n",
    "    time_dim['year'] = time_dim['date'].dt.year\n",
    "    time_dim['month'] = time_dim['date'].dt.month\n",
    "    time_dim['day'] = time_dim['date'].dt.day\n",
    "\n",
    "    #Merging time dimension with sales_data\n",
    "    sales_data['sale_date'] = pd.to_datetime(sales_data['sale_date'], errors='coerce')\n",
    "    sales_data = pd.merge(\n",
    "        sales_data,\n",
    "        time_dim[['date', 'date_id']],\n",
    "        left_on='sale_date',\n",
    "        right_on='date',\n",
    "        how='left'\n",
    "    )\n",
    "    sales_data.drop(columns=['sale_date', 'date'], inplace=True)\n",
    "    time_dim.drop(columns=['date'],inplace=True)\n",
    "\n",
    "\n",
    "    # Enriching the customer_data with the country\n",
    "    cities = customer_data['city'].unique()\n",
    "    countries = await get_all_countries(cities)\n",
    "    countries_dict = dict(countries)\n",
    "    customer_data['country'] = customer_data['city'].apply(lambda city: countries_dict.get(city, None))\n",
    "\n",
    "    #Create location dimension with unique city and country combinations\n",
    "    location_dim = customer_data[['city', 'country']].drop_duplicates()\n",
    "\n",
    "    # Assign a unique location_id for each unique city-country combination\n",
    "    location_dim['location_id'] = range(1, len(location_dim) + 1)\n",
    "\n",
    "    # Merge location_dim with customer_data to get customer_id associated with location_id\n",
    "    customer_location_mapping = customer_data[['customer_id', 'city', 'country']]\n",
    "    customer_location_mapping = pd.merge(customer_location_mapping, location_dim, on=['city', 'country'], how='left')\n",
    "\n",
    "    # Merge sales_data with the customer_location_mapping to add location_id\n",
    "    sales_data = pd.merge(\n",
    "        sales_data, \n",
    "        customer_location_mapping[['customer_id', 'location_id']], \n",
    "        on='customer_id', \n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    # Finalize location_dim (city and country are already unique)\n",
    "    location_dim = location_dim[['location_id', 'city', 'country']]\n",
    "\n",
    "    # Create product dimension\n",
    "    product_dim = product_data[['product_id', 'product_name', 'category']].drop_duplicates()\n",
    "\n",
    "    # Create customer dimension\n",
    "    customer_dim = customer_data[['customer_id', 'customer_name', 'age', 'gender']].drop_duplicates()\n",
    "    \n",
    "    # Keep only specific columns in the sales_data DataFrame\n",
    "    sales_data = sales_data[['customer_id', 'product_id', 'location_id', 'date_id', 'quantity', 'revenue', 'cost']]\n",
    "    sales_data['sale_id'] = range(1, len(sales_data) + 1)\n",
    "\n",
    "    sales_data = sales_data[['sale_id', 'customer_id', 'product_id', 'location_id', 'date_id', 'quantity', 'revenue', 'cost']]\n",
    "    customer_dim['gender'] = customer_dim['gender'].map({'Male': 0, 'Female': 1})\n",
    "    return sales_data, product_dim, customer_dim, location_dim, time_dim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "Base = declarative_base()\n",
    "\n",
    "class ProductDim(Base):\n",
    "    __tablename__ = 'product_dim'\n",
    "    product_id = Column(Integer, primary_key=True)\n",
    "    product_name = Column(String(255))\n",
    "    category = Column(String(100))\n",
    "\n",
    "\n",
    "class CustomerDim(Base):\n",
    "    __tablename__ = 'customer_dim'\n",
    "    customer_id = Column(Integer, primary_key=True)\n",
    "    customer_name = Column(String(255))\n",
    "    age = Column(Integer)\n",
    "    gender = Column(String(10))\n",
    "\n",
    "\n",
    "class LocationDim(Base):\n",
    "    __tablename__ = 'location_dim'\n",
    "    location_id = Column(Integer, primary_key=True)\n",
    "    city = Column(String(100))\n",
    "    country = Column(String(100))\n",
    "\n",
    "\n",
    "class TimeDim(Base):\n",
    "    __tablename__ = 'time_dim'\n",
    "    date_id = Column(Integer, primary_key=True)\n",
    "    year = Column(Integer)\n",
    "    month = Column(Integer)\n",
    "    day = Column(Integer)\n",
    "\n",
    "\n",
    "class SalesFact(Base):\n",
    "    __tablename__ = 'sales_fact'\n",
    "    sale_id = Column(Integer, primary_key=True)\n",
    "    customer_id = Column(Integer, ForeignKey('customer_dim.customer_id'))\n",
    "    product_id = Column(Integer, ForeignKey('product_dim.product_id'))\n",
    "    location_id = Column(Integer, ForeignKey('location_dim.location_id'))\n",
    "    date_id = Column(Integer, ForeignKey('time_dim.date_id'))\n",
    "    quantity = Column(Integer)\n",
    "    revenue = Column(Float)\n",
    "    cost = Column(Float)\n",
    "\n",
    "\n",
    "def load(sales_fact, product_dim, customer_dim, location_dim, time_dim):\n",
    "    try:\n",
    "        #SQLAlchemy connection string\n",
    "        engine = create_engine(\n",
    "            'mssql+pyodbc://server_name/test?driver=ODBC+Driver+17+for+SQL+Server&trusted_connection=yes'\n",
    "        )\n",
    "\n",
    "        #Verify connection\n",
    "        with engine.connect() as conn:\n",
    "            print(\"Connected to the database successfully.\")\n",
    "\n",
    "        #Create tables\n",
    "        Base.metadata.create_all(engine)\n",
    "\n",
    "        #Load data into tables\n",
    "        tables = {\n",
    "            SalesFact: sales_fact,\n",
    "            ProductDim: product_dim,\n",
    "            CustomerDim: customer_dim,\n",
    "            LocationDim: location_dim,\n",
    "            TimeDim: time_dim\n",
    "        }\n",
    "\n",
    "        for table_class, df in tables.items():\n",
    "            df.to_sql(\n",
    "                table_class.__tablename__,\n",
    "                con=engine,\n",
    "                schema='dbo',\n",
    "                if_exists='replace',\n",
    "                index=False,\n",
    "                chunksize=1000\n",
    "            )\n",
    "            print(f\"Data successfully loaded into {table_class.__tablename__}.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_4496\\2956899493.py:7: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  sales_2022_data = pd.read_sql(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully fetched sales_2022 data.\n",
      "Successfully loaded sales_2023 data.\n",
      "Successfully loaded customer data.\n",
      "Successfully loaded product data.\n",
      "Connected to the database successfully.\n",
      "Data successfully loaded into sales_fact.\n",
      "Data successfully loaded into product_dim.\n",
      "Data successfully loaded into customer_dim.\n",
      "Data successfully loaded into location_dim.\n",
      "Data successfully loaded into time_dim.\n"
     ]
    }
   ],
   "source": [
    "sales_2022_data,sales_2023_data,customer_data,product_data=extract();\n",
    "sales_fact, product_dim, customer_dim, location_dim, time_dim = await transform(sales_2022_data, sales_2023_data, product_data, customer_data)\n",
    "#print(sales_fact)\n",
    "load(sales_fact,product_dim,customer_dim,location_dim,time_dim)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
